<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Using uncertainty sampling &middot; modAL
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="public/css/poole.css">
  <link rel="stylesheet" href="public/css/syntax.css">
  <link rel="stylesheet" href="public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="index">
          modAL
        </a>
      </h1>
      <p class="lead">A modular active learning framework for Python3</p>
    </div>

    <nav class="sidebar-nav">
      <b>Overview</b>
        <a class="sidebar-nav-item" href="index">modAL in a nutshell</a>
        <a class="sidebar-nav-item" href="Installation">Installation</a>
      <b>Models</b>
        <a class="sidebar-nav-item" href="ActiveLearner">ActiveLearner</a>
        <a class="sidebar-nav-item" href="Committee">Committee</a>
      <b>Query strategies</b>
        <a class="sidebar-nav-item" href="Uncertainty-sampling">Uncertainty sampling</a>
        <a class="sidebar-nav-item" href="Disagreement-sampling">Disagreement sampling</a>
        <a class="sidebar-nav-item" href="Extending-modAL">Extending modAL</a>
      <b>Examples</b>
        <a class="sidebar-nav-item" href="Pool-based-sampling">Pool-based sampling</a>
        <a class="sidebar-nav-item" href="Stream-based-sampling">Stream-based sampling</a>
        <a class="sidebar-nav-item" href="Active-regression">Active regression</a>
        <a class="sidebar-nav-item" href="Query-by-committee">Query by committee</a>
        <a class="sidebar-nav-item" href="Bootstrapping-and-bagging">Bootstrapping and bagging</a>
        <a class="sidebar-nav-item" href="Keras-integration">Keras integration</a>
      <b>API reference</b>
        <a class="sidebar-nav-item" href="Models-API">modAL.models</a>
        <a class="sidebar-nav-item" href="Uncertainty-sampling-API">modAL.uncertainty</a>
        <a class="sidebar-nav-item" href="Disagreement-sampling-API">modAL.disagreement</a>
    </nav>

    <p>&copy; <a href="https://github.com/poole/hyde">Theme</a> by Mark Otto</p>
  </div>
</div>


    <div class="content container">
      <div class="page">
  <h1 id="using-uncertainty-sampling">Using uncertainty sampling</h1>
<p>When you present unlabelled examples to an active learner, it finds you the most <em>useful</em> example and presents it for you to be labelled. This is done by first calculating the <em>usefulness</em> of prediction (whatever it means) for each example and select an instance based on the usefulness. The thing is, there are several ways to measure this. They are based upon the classification uncertainty, hence they are called <em>uncertainty measures</em>. In modAL, currently you can select from three built-in measures: <em>classification uncertainty</em>, <em>classification margin</em> and <em>classification entropy</em>. In the following, these are shortly reviewed. For more details, see Section 2.3 of the awesome book <em>Active learning</em> by Burr Settles.</p>

<h2 id="page-contents">Page contents</h2>
<ul>
  <li><a href="#uncertainty">Classification uncertainty</a></li>
  <li><a href="#margin">Classification margin</a></li>
  <li><a href="#entropy">Classification entropy</a></li>
</ul>

<h2 id="classification-uncertainty">Classification uncertainty<a name="uncertainty"></a></h2>
<p>The simplest measure is the uncertainty of classification defined by</p>

<p><img src="https://chart.apis.google.com/chart?cht=tx&amp;chl=U(x)=1-P(\hat{x}|x)" alt="cu-def" /></p>

<p>where <img src="https://chart.apis.google.com/chart?cht=tx&amp;chl=x" alt="cu-x" /> is the instance to be predicted and <img src="https://chart.apis.google.com/chart?cht=tx&amp;chl=\hat{x}" alt="cu-xhat" /> is the most likely prediction.</p>

<p>For example, if you have classes <code class="highlighter-rouge">[0, 1, 2]</code> and classification probabilities <code class="highlighter-rouge">[0.1, 0.2, 0.7]</code>, the most likely class according to the classifier is <code class="highlighter-rouge">2</code> with uncertainty 0.3. If you have three instances with class probabilities</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">proba</span>
<span class="o">...</span> <span class="p">[[</span><span class="mf">0.1</span> <span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">]</span>
<span class="o">...</span>  <span class="p">[</span><span class="mf">0.6</span> <span class="p">,</span> <span class="mf">0.3</span> <span class="p">,</span> <span class="mf">0.1</span> <span class="p">]</span>
<span class="o">...</span>  <span class="p">[</span><span class="mf">0.39</span><span class="p">,</span> <span class="mf">0.61</span><span class="p">,</span> <span class="mf">0.0</span> <span class="p">]]</span>
</code></pre></div></div>
<p>the corresponding uncertainties are</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">uncertainty</span>
<span class="o">...</span> <span class="p">[</span><span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.39</span><span class="p">]</span>
</code></pre></div></div>
<p>In the above example, the most uncertain sample is the second one. When querying for labels based on this measure, the strategy selects the sample with the highest uncertainty.</p>

<p>For this ternary classification problem, given the first two probabilities, the classification uncertainty looks like the following.</p>

<p><img src="/img/uncertainty.png" alt="cu-plot" /></p>

<h2 id="classification-margin">Classification margin<a name="margin"></a></h2>

<p>Classification margin is the difference in probability of the first and second most likely prediction, that is, it is defined by</p>

<p><img src="https://chart.apis.google.com/chart?cht=tx&amp;chl=M(x)=P(\hat{x_1}|x)-P(\hat{x_2}|x)" alt="cm-def" /></p>

<p>where <img src="https://chart.apis.google.com/chart?cht=tx&amp;chl=\hat{x_1}" alt="cm-x1" /> and <img src="https://chart.apis.google.com/chart?cht=tx&amp;chl=\hat{x_2}" alt="cm-x2" /> are the first and second most likely classes. Using the same example we used for classification uncertainty, if the class probabilities are</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">proba</span>
<span class="o">...</span> <span class="p">[[</span><span class="mf">0.1</span> <span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">]</span>
<span class="o">...</span>  <span class="p">[</span><span class="mf">0.6</span> <span class="p">,</span> <span class="mf">0.3</span> <span class="p">,</span> <span class="mf">0.1</span> <span class="p">]</span>
<span class="o">...</span>  <span class="p">[</span><span class="mf">0.39</span><span class="p">,</span> <span class="mf">0.61</span><span class="p">,</span> <span class="mf">0.0</span> <span class="p">]]</span>
</code></pre></div></div>
<p>the corresponding margins are</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">margin</span>
<span class="o">...</span> <span class="p">[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.22</span><span class="p">]</span>
</code></pre></div></div>
<p>When querying for labels, the strategy selects the sample with the <em>smallest</em> margin, since the smaller the decision margin is, the more unsure the decision. In this case, it would be the third sample. For this ternary classification problem, the classifier margin plotted against the first two probabilities are the following.</p>

<p><img src="/img/margin.png" alt="cm-plot" /></p>

<h2 id="classification-entropy">Classification entropy<a name="entropy"></a></h2>

<p>The third built-in uncertainty measure is the classification entropy, which is defined by</p>

<p><img src="https://chart.apis.google.com/chart?cht=tx&amp;chl=H(x)=-\sum_{k}p_k\log(p_k)" alt="ce-def" /></p>

<p>where <img src="https://chart.apis.google.com/chart?cht=tx&amp;chl=p_k" alt="ce-class" /> is the probability of the sample belonging to the <em>k</em>-th class. Heuristically, the entropy is proportional to the average number of guesses one has to make to find the true class. In our usual example</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">proba</span>
<span class="o">...</span> <span class="p">[[</span><span class="mf">0.1</span> <span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">]</span>
<span class="o">...</span>  <span class="p">[</span><span class="mf">0.6</span> <span class="p">,</span> <span class="mf">0.3</span> <span class="p">,</span> <span class="mf">0.1</span> <span class="p">]</span>
<span class="o">...</span>  <span class="p">[</span><span class="mf">0.39</span><span class="p">,</span> <span class="mf">0.61</span><span class="p">,</span> <span class="mf">0.0</span> <span class="p">]]</span>
</code></pre></div></div>
<p>the corresponding entropies are approximately</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">entropy</span>
<span class="o">...</span> <span class="p">[</span><span class="mf">0.5181</span><span class="p">,</span> <span class="mf">0.8979</span><span class="p">,</span> <span class="mf">0.6687</span><span class="p">]</span>
</code></pre></div></div>
<p>The closer the distribution to uniform, the larger the entropy. Again, if we plot the entropy against the first two probabilities of a ternary classification problem, we obtain the following.</p>

<p><img src="/img/entropy.png" alt="ce-plot" /></p>


</div>

    </div>

  </body>
</html>
