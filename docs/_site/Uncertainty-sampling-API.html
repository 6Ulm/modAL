<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      The modAL.uncertainty module &middot; modAL
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="public/css/poole.css">
  <link rel="stylesheet" href="public/css/syntax.css">
  <link rel="stylesheet" href="public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="index">
          modAL
        </a>
      </h1>
      <p class="lead">A modular active learning framework for Python3</p>
    </div>

    <nav class="sidebar-nav">
      <b>Overview</b>
        <a class="sidebar-nav-item" href="index">modAL in a nutshell</a>
        <a class="sidebar-nav-item" href="Installation">Installation</a>
      <b>Models</b>
        <a class="sidebar-nav-item" href="ActiveLearner">ActiveLearner</a>
        <a class="sidebar-nav-item" href="Committee">Committee</a>
      <b>Query strategies</b>
        <a class="sidebar-nav-item" href="Uncertainty-sampling">Uncertainty sampling</a>
        <a class="sidebar-nav-item" href="Disagreement-sampling">Disagreement sampling</a>
        <a class="sidebar-nav-item" href="Extending-modAL">Extending modAL</a>
      <b>Examples</b>
        <a class="sidebar-nav-item" href="Pool-based-sampling">Pool-based sampling</a>
        <a class="sidebar-nav-item" href="Stream-based-sampling">Stream-based sampling</a>
        <a class="sidebar-nav-item" href="Active-regression">Active regression</a>
        <a class="sidebar-nav-item" href="Query-by-committee">Query by committee</a>
        <a class="sidebar-nav-item" href="Bootstrapping-and-bagging">Bootstrapping and bagging</a>
        <a class="sidebar-nav-item" href="Keras-integration">Keras integration</a>
      <b>API reference</b>
        <a class="sidebar-nav-item" href="Models-API">modAL.models</a>
        <a class="sidebar-nav-item" href="Uncertainty-sampling-API">modAL.uncertainty</a>
        <a class="sidebar-nav-item" href="Disagreement-sampling-API">modAL.disagreement</a>
    </nav>

    <p>&copy; <a href="https://github.com/poole/hyde">Theme</a> by Mark Otto</p>
  </div>
</div>


    <div class="content container">
      <div class="page">
  <h1 id="the-modaluncertainty-module">The modAL.uncertainty module</h1>
<p>The module contains two type of functions: uncertainty measures and sampling strategies. Uncertainty measures take a classifier and an array of samples as input and they return an array of corresponding uncertainties. Sampling strategies take the same input but they return the samples to be labelled by the Oracle.</p>

<h2 id="page-contents">Page contents</h2>
<ul>
  <li><a href="#query-strategies">Query strategies</a>
    <ul>
      <li><a href="#uncertainty-sampling">Uncertainty sampling</a></li>
      <li><a href="#margin-sampling">Margin sampling</a></li>
      <li><a href="#entropy-sampling">Entropy sampling</a></li>
    </ul>
  </li>
  <li><a href="#uncertainty-measures">Uncertainty measures</a>
    <ul>
      <li><a href="#classifier-uncertainty">Classifier uncertainty</a></li>
      <li><a href="#classifier-margin">Classifier margin</a></li>
      <li><a href="#classifier-entropy">Classifier entropy</a></li>
    </ul>
  </li>
</ul>

<h1 id="query-strategies">Query strategies<a name="query-strategies"></a></h1>

<h2 id="uncertainty-sampling">Uncertainty sampling<a name="uncertainty-sampling"></a></h2>

<p><code class="highlighter-rouge">uncertainty_sampling(classifier, X, n_instances=1, **uncertainty_measure_kwargs)</code></p>

<p>Uncertainty sampling query strategy. Selects the least sure instances for labelling.</p>

<p><strong>Parameters</strong><br />
<em>classifier</em>: sklearn classifier object, for instance sklearn.ensemble.RandomForestClassifier<br />
    The classifier for which the labels are to be queried.</p>

<p><em>X</em>: numpy.ndarray of shape (n_samples, n_features)<br />
    The pool of samples to query from.</p>

<p><em>n_instances</em>: int<br />
    Number of samples to be queried.</p>

<p><em>uncertainty_measure_kwargs</em>: keyword arguments<br />
    Keyword arguments to be passed for the uncertainty measure function.</p>

<p><strong>Returns</strong><br />
<em>query_idx</em>: numpy.ndarray of shape (n_instances, )<br />
    The indices of the instances from X_pool chosen to be labelled.</p>

<p><em>X_pool[query_idx]</em>: numpy.ndarray of shape (n_instances, n_features)<br />
    The instances from X_pool chosen to be labelled.</p>

<h2 id="margin-sampling">Margin sampling<a name="margin-sampling"></a></h2>

<p><code class="highlighter-rouge">margin_sampling(classifier, X, n_instances=1, **uncertainty_measure_kwargs)</code></p>

<p>Margin sampling query strategy. Selects the instances where the difference between
the first most likely and second most likely classes are the smallest.</p>

<p><strong>Parameters</strong><br />
<em>classifier</em>: sklearn classifier object, for instance sklearn.ensemble.RandomForestClassifier<br />
    The classifier for which the labels are to be queried.</p>

<p><em>X</em>: numpy.ndarray of shape (n_samples, n_features)<br />
    The pool of samples to query from.</p>

<p><em>n_instances</em>: int<br />
    Number of samples to be queried.</p>

<p><em>uncertainty_measure_kwargs</em>: keyword arguments<br />
    Keyword arguments to be passed for the uncertainty measure function.</p>

<p><strong>Returns</strong><br />
<em>query_idx</em>: numpy.ndarray of shape (n_instances, )<br />
    The indices of the instances from X_pool chosen to be labelled.</p>

<p><em>X_pool[query_idx]</em>: numpy.ndarray of shape (n_instances, n_features)<br />
    The instances from X_pool chosen to be labelled.</p>

<h2 id="entropy-sampling">Entropy sampling<a name="entropy-sampling"></a></h2>

<p><code class="highlighter-rouge">entropy_sampling(classifier, X, n_instances=1, **uncertainty_measure_kwargs)</code></p>

<p>Entropy sampling query strategy. Selects the instances where the class probabilities
have the largest entropy.</p>

<p><strong>Parameters</strong><br />
<em>classifier</em>: sklearn classifier object, for instance sklearn.ensemble.RandomForestClassifier<br />
    The classifier for which the labels are to be queried.</p>

<p><em>X</em>: numpy.ndarray of shape (n_samples, n_features)<br />
    The pool of samples to query from.</p>

<p><em>n_instances</em>: int<br />
    Number of samples to be queried.</p>

<p><em>uncertainty_measure_kwargs</em>: keyword arguments<br />
    Keyword arguments to be passed for the uncertainty measure function.</p>

<p><strong>Returns</strong><br />
<em>query_idx</em>: numpy.ndarray of shape (n_instances, )<br />
    The indices of the instances from X_pool chosen to be labelled.</p>

<p><em>X_pool[query_idx]</em>: numpy.ndarray of shape (n_instances, n_features)<br />
    The instances from X_pool chosen to be labelled.</p>

<hr />

<h1 id="uncertainty-measures">Uncertainty measures<a name="uncertainty-measures"></a></h1>

<h2 id="classifier-uncertainty">Classifier uncertainty<a name="classifier-uncertainty"></a></h2>

<p><code class="highlighter-rouge">classifier_uncertainty(classifier, X, **predict_proba_kwargs)</code></p>

<p>Classification uncertainty of the classifier for the provided samples.</p>

<p><strong>Parameters</strong><br />
<em>classifier</em>: sklearn classifier object, for instance sklearn.ensemble.RandomForestClassifier<br />
    The classifier for which the uncertainty is to be measured.</p>

<p><em>X</em>: numpy.ndarray of shape (n_samples, n_features)<br />
    The samples for which the uncertainty of classification is to be measured.</p>

<p><em>predict_proba_kwargs</em>: keyword arguments<br />
    Keyword arguments to be passed for the predict_proba method of the classifier.</p>

<p><strong>Returns</strong><br />
<em>uncertainty</em>: numpy.ndarray of shape (n_samples, )<br />
    Classifier uncertainty, which is 1 - P(prediction is correct).</p>

<p><strong>References</strong><br />
[1] Settles, Burr: Active Learning, (Morgan &amp; Claypool Publishers), equation no. (2.1)</p>

<h2 id="classifier-margin">Classifier margin<a name="classifier-margin"></a></h2>

<p><code class="highlighter-rouge">classifier_margin(classifier, X, **predict_proba_kwargs)</code></p>

<p>Classification margin uncertainty of the classifier for the provided samples.
This uncertainty measure takes the first and second most likely predictions
and takes the difference of their probabilities, which is the margin.</p>

<p><strong>Parameters</strong><br />
<em>classifier</em>: sklearn classifier object, for instance sklearn.ensemble.RandomForestClassifier<br />
    The classifier for which the uncertainty is to be measured</p>

<p><em>X</em>: numpy.ndarray of shape (n_samples, n_features)<br />
    The samples for which the uncertainty of classification is to be measured</p>

<p><em>predict_proba_kwargs</em>: keyword arguments<br />
    Keyword arguments to be passed for the predict_proba method of the classifier</p>

<p><strong>Returns</strong><br />
<em>margin</em>: numpy.ndarray of shape (n_samples, )<br />
    Margin uncertainty, which is the difference of the probabilities of first
    and second most likely predictions.</p>

<p><strong>References</strong><br />
[1] Settles, Burr: Active Learning, (Morgan &amp; Claypool Publishers), equation no. (2.2)</p>

<h2 id="classifier-entropy">Classifier entropy<a name="classifier-entropy"></a></h2>

<p><code class="highlighter-rouge">classifier_entropy(classifier, X, **predict_proba_kwargs)</code></p>

<p>Entropy of predictions of the for the provided samples.</p>

<p><strong>Parameters</strong><br />
<em>classifier</em>: sklearn classifier object, for instance sklearn.ensemble.RandomForestClassifier<br />
    The classifier for which the prediction entropy is to be measured.</p>

<p><em>X</em>: numpy.ndarray of shape (n_samples, n_features)<br />
    The samples for which the prediction entropy is to be measured.</p>

<p><em>predict_proba_kwargs</em>: keyword arguments<br />
    Keyword arguments to be passed for the predict_proba method of the classifier.</p>

<p><strong>Returns</strong><br />
<em>entr</em>: numpy.ndarray of shape (n_samples, )<br />
    Entropy of the class probabilities.</p>

<p><strong>References</strong><br />
[1] Settles, Burr: Active Learning, (Morgan &amp; Claypool Publishers), equation no. (2.3)</p>

</div>

    </div>

  </body>
</html>
